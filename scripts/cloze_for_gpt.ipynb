{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/efittsc1/projects/historical-perspectival-lm/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import torch\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluation_file = \"/home/sli159/projects/historical-perspectival-lm/data/evaluation_dataset.jsonl\"\n",
    "\n",
    "evaluation_dataset = []\n",
    "with open(evaluation_file, \"r\") as f:\n",
    "    for line in f:\n",
    "        evaluation_dataset.append(json.loads(line))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading checkpoint shards: 100%|██████████| 7/7 [00:04<00:00,  1.75it/s]\n"
     ]
    }
   ],
   "source": [
    "model_path = \"Hplm/student_model_1850_1880\" # \"Hplm/dora_llama_model_1850_1880\" #\n",
    "model = AutoModelForCausalLM.from_pretrained(model_path, torch_dtype=torch.float16, device_map=\"cuda:0\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_rank(logits, token):\n",
    "    probabilities = torch.nn.functional.softmax(logits, dim=1)\n",
    "    token_prob = probabilities[0][token]\n",
    "    rank = torch.sum(probabilities > token_prob) + 1\n",
    "    return rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_token(offset_mapping, word_start_index):\n",
    "    for i, (start, end) in enumerate(offset_mapping):\n",
    "        if start == word_start_index:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:26<00:00, 37.79it/s]\n"
     ]
    }
   ],
   "source": [
    "results = []\n",
    "with torch.no_grad():\n",
    "    for example in tqdm(evaluation_dataset[:1000]):\n",
    "        inputs = tokenizer(example[\"text\"], return_tensors=\"pt\", return_offsets_mapping=True).to(\"cuda:0\")\n",
    "        token_index = get_token(inputs[\"offset_mapping\"][0], example[\"word_index\"])\n",
    "        if token_index == -1:\n",
    "            token_index = get_token(inputs[\"offset_mapping\"][0], example[\"word_index\"]-1)\n",
    "        assert token_index != -1, \"Token not found \\n\" + str(inputs[\"offset_mapping\"]) + \"\\n\" + str(example[\"word_index\"])\n",
    "        outputs = model(**inputs)\n",
    "        token_logit = outputs.logits[:, token_index-1]\n",
    "        target_token = inputs[\"input_ids\"][0][token_index]\n",
    "        rank = calculate_rank(token_logit, inputs[\"input_ids\"][0][token_index])\n",
    "\n",
    "        assert target_token == tokenizer(example[\"completion_word\"], return_tensors=\"pt\", add_special_tokens=False)[\"input_ids\"][0][0], f\"Token mismatch {target_token} != {tokenizer(example['completion_word'], return_tensors='pt')['input_ids'][0][0]}, '{tokenizer.decode([target_token])}' != '{example['completion_word']}'\"\n",
    "\n",
    "        results.append({\n",
    "            \"example\" : example,\n",
    "            \"rank\" : rank.item(),\n",
    "            \"inputs\" : inputs,\n",
    "            \"logit\" : token_logit.cpu().numpy(),\n",
    "        })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Give him but Sage and Butter..And there's no fear .\",\n",
       " 'word_index': 45,\n",
       " 'stem': \"Give him but Sage and Butter..And there's no\",\n",
       " 'completion_word': ' fear',\n",
       " 'completion': ' fear .',\n",
       " 'word': 'fear',\n",
       " 'link': '/dictionary/fear_n?tab=factsheet#4529006',\n",
       " 'sense_start_year': 1535,\n",
       " 'sense_end_year': None,\n",
       " 'citation_year': 1640}"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_results(results, time):\n",
    "    before = []\n",
    "    after = []\n",
    "    for result in results:\n",
    "        if result[\"example\"][\"sense_start_year\"] < time:\n",
    "            before.append(result)\n",
    "        else:\n",
    "            after.append(result)\n",
    "    return before, after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_statistics(results):\n",
    "    ranks = [result[\"rank\"] for result in results]\n",
    "    print(\"Mean rank: \", sum(ranks) / len(ranks))\n",
    "    print(\"Median rank: \", sorted(ranks)[len(ranks) // 2])\n",
    "    print(f\"Top 1: {sum(1 for rank in ranks if rank <= 1)}/{len(ranks)} - {sum(1 for rank in ranks if rank <= 1) / len(ranks)}\")\n",
    "    print(f\"Top 50: {sum(1 for rank in ranks if rank <= 50)}/{len(ranks)} - {sum(1 for rank in ranks if rank <= 50) / len(ranks)}\")\n",
    "    print(f\"Top 100: {sum(1 for rank in ranks if rank <= 100)}/{len(ranks)} - {sum(1 for rank in ranks if rank <= 100) / len(ranks)}\")\n",
    "    print(f\"Top 1000: {sum(1 for rank in ranks if rank <= 1000)}/{len(ranks)} - {sum(1 for rank in ranks if rank <= 1000) / len(ranks)}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 1880\n",
      "Mean rank:  434.02389078498294\n",
      "Median rank:  11\n",
      "Top 1: 172/879 - 0.1956769055745165\n",
      "Top 50: 595/879 - 0.676905574516496\n",
      "Top 100: 659/879 - 0.7497155858930603\n",
      "Top 1000: 813/879 - 0.9249146757679181\n",
      "--------------------------------------------------\n",
      "After 1880\n",
      "Mean rank:  859.8677685950413\n",
      "Median rank:  41\n",
      "Top 1: 19/121 - 0.15702479338842976\n",
      "Top 50: 65/121 - 0.5371900826446281\n",
      "Top 100: 79/121 - 0.6528925619834711\n",
      "Top 1000: 104/121 - 0.859504132231405\n"
     ]
    }
   ],
   "source": [
    "year = 1880\n",
    "before, after = split_results(results, year)\n",
    "print(f\"Before {year}\")\n",
    "print_statistics(before)\n",
    "print(\"-\" * 50)\n",
    "print(f\"After {year}\")\n",
    "print_statistics(after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before 1850\n",
      "Mean rank:  1289.6\n",
      "Median rank:  380\n",
      "Top 1: 14/770 - 0.01818181818181818\n",
      "Top 50: 148/770 - 0.19220779220779222\n",
      "Top 100: 210/770 - 0.2727272727272727\n",
      "Top 1000: 519/770 - 0.674025974025974\n",
      "--------------------------------------------------\n",
      "After 1850\n",
      "Mean rank:  1956.0304347826086\n",
      "Median rank:  989\n",
      "Top 1: 1/230 - 0.004347826086956522\n",
      "Top 50: 20/230 - 0.08695652173913043\n",
      "Top 100: 38/230 - 0.16521739130434782\n",
      "Top 1000: 117/230 - 0.508695652173913\n"
     ]
    }
   ],
   "source": [
    "before, after = split_results(results, 1820)\n",
    "print(\"Before 1850\")\n",
    "print_statistics(before)\n",
    "print(\"-\" * 50)\n",
    "print(\"After 1850\")\n",
    "print_statistics(after)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
