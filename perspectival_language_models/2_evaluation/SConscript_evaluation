import os
import os.path
import json
from steamroller_utils import cpu_task_config, gpu_task_config
from steamroller import Environment
from collections import defaultdict


vars = Variables("custom_evaluation.py")
vars.AddVariables(
    # Work directory
    ("ORIGINAL_WORK_DIR", "", "work"),
    ("WORK_DIR", "", "work"),

    # Random Seed
    ("RANDOM_SEED", "", 42),

    # Evaluation settings
    ("MIN_OCCURRENCE_EVALUATION", "", 2),

    # STEAMROLLER settings
    ("STEAMROLLER_ENGINE", "", "slurm"),
    ("CPU_QUEUE", "", "parallel"),
    ("CPU_ACCOUNT", "", "tlippin1"),    
    ("GPU_QUEUE", "", "a100"),
    ("GPU_ACCOUNT", "", "tlippin1_gpu"),
    ("GPU_COUNT", "", 1),
    ("MEMORY", "", "64GB")
)

env = Environment(
    variables=vars,
    BUILDERS={
        "BLIMP_to_CSV" : Builder(
            action = (
                "python scripts/blimp_to_csv.py "
                "--blimp_directories ${SOURCES} "
                "--blimp_identifiers ${IDENTIFIERS} "
                "--output_directory ${TARGET}"
            )
        ),
        "START_EVALUATION" : Builder(
            action = (
                "python scripts/start_evaluation.py "
                "--model_dir ${SOURCES[0]} "
                "--tasks ${TASK} "
                "--output ${TARGET}"
            )
        ),
        "FILTER_EVALUATION" : Builder(
            action = (
                "python scripts/filter_evaluation.py "
                "--data ${SOURCES[1:]} "
                "--evaluation_result ${SOURCES[0]} "
                "--min_occurrence ${MIN_OCCURRENCE_EVALUATION} "
                "--output ${TARGET} "
            )
        ),
        "CrossTimePerplexity" : Builder(
            action = (
                "python scripts/cross_time_perplexity.py "
                "--models ${MODELS} "
                "--test_sets ${TEST_SETS} "
                "--tokenizers ${TOKENIZERS} "
                "--time_data ${TIME_DATA} "
                "--output ${TARGET}"
            )
        ),
    }
)

Import("training_data")
Import("pretrained_results")
Import("finetuned_results")

print(pretrained_results.keys())
print(finetuned_results.keys())
print(training_data.keys())

all_train_data = [slice["train"] for slice in training_data.values()]
all_models = []


for slice, data in training_data.items():
    if slice in pretrained_results:
        pretrained_models = pretrained_results[slice]
        all_models.extend([
            ("pretrained_student", pretrained_models["student"], slice, data, 
            pretrained_models["tokenizer"]), 
            ("pretrained_teacher_1", pretrained_models["teacher_1"], slice, data, 
             pretrained_models["tokenizer"]), 
            ("pretrained_teacher_2", pretrained_models["teacher_2"], slice, data, 
             pretrained_models["tokenizer"]),
        ])
    if slice in finetuned_results:
        finetuned_models = finetuned_results[slice]
        all_models.extend([
            ("finetuned_model", finetuned_models["model"], slice, data, finetuned_models["tokenizer"]),
        ])


all_evaluation_results = defaultdict(list)

for model_name, model, slice, data, _ in all_models:
    for task_name in ["blimp", "ewok_filtered", "historical_mp"]:
        task_result = env.START_EVALUATION(
            source = [model],
            target = "${WORK_DIR}" + f"/{slice}/{model_name}/{task_name}",
            TASK = task_name,
            **gpu_task_config(env,f"{model_name}_{task_name}", "01:30:00", "24GB")
        )
        filtered_result = env.FILTER_EVALUATION(
            source = [task_result, data["train"]],
            target = "${WORK_DIR}" +f"/{slice}/{model_name}/{task_name}_filtered",
            MIN_OCCURRENCE = env["MIN_OCCURRENCE_EVALUATION"],
            **cpu_task_config(env,f"FILTER_{model_name}_{task_name}", "00:30:00", "24GB")
        )
        maximal_filtered_result = env.FILTER_EVALUATION(
            source = [task_result, all_train_data],
            target = "${WORK_DIR}" +f"/{slice}/{model_name}/{task_name}_maximal_filtered",
            MIN_OCCURRENCE = env["MIN_OCCURRENCE_EVALUATION"],
            **cpu_task_config(env,f"MAX_FILTER_{model_name}_{task_name}", "00:30:00", "24GB")
        )
        all_evaluation_results[task_name].append((task_result, f"{model_name}_{slice}"))
        all_evaluation_results[task_name].append((filtered_result, f"{model_name}_{slice}_filtered"))
        all_evaluation_results[task_name].append((maximal_filtered_result, f"{model_name}_{slice}_maximal_filtered"))

all_blimp, all_identifiers = zip(*all_evaluation_results["blimp"])

env.BLIMP_to_CSV(
        source = all_blimp,
        target = "${WORK_DIR}/combined_BLIMP_filtered/",
        IDENTIFIERS = all_identifiers,
        **cpu_task_config(env,"BLIMP_to_CSV", "00:30:00", "24GB")
    )

_, all_models, all_slices, all_data, all_tokenizers = zip(*all_models)
all_test_sets = [data["test"] for data in all_data]

env.CrossTimePerplexity(
    source = [all_models, all_test_sets, all_tokenizers],
    target = "${WORK_DIR}/cross_time_perplexity",
    TIME_DATA = all_slices,
    MODELS = all_models,
    TEST_SETS = all_test_sets,
    TOKENIZERS = all_tokenizers,
    **gpu_task_config(env,"CrossTimePerplexity", "03:30:00", "48GB")
)



